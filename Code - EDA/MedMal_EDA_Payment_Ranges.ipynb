{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMc_daz1Ch7t"
      },
      "source": [
        "**Setup**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtHQYWAByld4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4920dded-26a9-468c-8af4-760c66356f85"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "from google.colab import drivew\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDKypIxba9JU",
        "outputId": "b7d17e49-d126-4ed3-8267-a8b2cf902a9a"
      },
      "source": [
        "!pip install s3fs\n",
        "import s3fs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting s3fs\n",
            "  Downloading s3fs-2021.11.1-py3-none-any.whl (25 kB)\n",
            "Collecting aiobotocore~=2.0.1\n",
            "  Downloading aiobotocore-2.0.1.tar.gz (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting aiohttp<=4\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 10.4 MB/s \n",
            "\u001b[?25hCollecting fsspec==2021.11.1\n",
            "  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 46.2 MB/s \n",
            "\u001b[?25hCollecting botocore<1.22.9,>=1.22.8\n",
            "  Downloading botocore-1.22.8-py3-none-any.whl (8.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.1 MB 24.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.10.10 in /usr/local/lib/python3.7/dist-packages (from aiobotocore~=2.0.1->s3fs) (1.13.3)\n",
            "Collecting aioitertools>=0.5.1\n",
            "  Downloading aioitertools-0.8.0-py3-none-any.whl (21 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 50.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<=4->s3fs) (21.2.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 55.8 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp<=4->s3fs) (3.10.0.2)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<=4->s3fs) (2.0.8)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 55.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.9,>=1.22.8->aiobotocore~=2.0.1->s3fs) (2.8.2)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 67.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.9,>=1.22.8->aiobotocore~=2.0.1->s3fs) (1.15.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp<=4->s3fs) (2.10)\n",
            "Building wheels for collected packages: aiobotocore\n",
            "  Building wheel for aiobotocore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aiobotocore: filename=aiobotocore-2.0.1-py3-none-any.whl size=51992 sha256=05171364d109fc7534a833142407c3de859578934e913bba1219db986a7ce96e\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/cd/99/917ef1080ec8cc6f1c903f4622761689c3886bc49306855a0e\n",
            "Successfully built aiobotocore\n",
            "Installing collected packages: multidict, frozenlist, yarl, urllib3, jmespath, asynctest, async-timeout, aiosignal, botocore, aioitertools, aiohttp, fsspec, aiobotocore, s3fs\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.7 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aiobotocore-2.0.1 aiohttp-3.8.1 aioitertools-0.8.0 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 botocore-1.22.8 frozenlist-1.2.0 fsspec-2021.11.1 jmespath-0.10.0 multidict-5.2.0 s3fs-2021.11.1 urllib3-1.26.7 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMX0ywTdCHue",
        "outputId": "8bbf300c-0604-4171-ceba-8d42defe5024"
      },
      "source": [
        "!pip install pandasql\n",
        "import pandasql as ps"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandasql\n",
            "  Downloading pandasql-0.7.3.tar.gz (26 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pandasql) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pandasql) (1.1.5)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from pandasql) (1.4.27)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->pandasql) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pandasql) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->pandasql) (1.15.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->pandasql) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->pandasql) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy->pandasql) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy->pandasql) (3.10.0.2)\n",
            "Building wheels for collected packages: pandasql\n",
            "  Building wheel for pandasql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandasql: filename=pandasql-0.7.3-py3-none-any.whl size=26781 sha256=0bd85e93dba9ff1102658a90257193d5eca9a9d91f7436ef0a939a3334ca4482\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/4b/ec/41f4e116c8053c3654e2c2a47c62b4fca34cc67ef7b55deb7f\n",
            "Successfully built pandasql\n",
            "Installing collected packages: pandasql\n",
            "Successfully installed pandasql-0.7.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzZ_NJPuCJvF"
      },
      "source": [
        "%%capture\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5EI4rFMCML8"
      },
      "source": [
        "%%capture\n",
        "!apt install libkrb5-dev\n",
        "!wget https://downloads.apache.org/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install findspark\n",
        "!pip install sparkmagic\n",
        "!pip install pyspark\n",
        "\n",
        "! pip install pyspark --user\n",
        "! pip install seaborn --user\n",
        "! pip install plotly --user\n",
        "! pip install imageio --user\n",
        "! pip install folium --user"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHe4dlHaCOU0"
      },
      "source": [
        "%%capture\n",
        "!apt update\n",
        "!apt install gcc python-dev libkrb5-dev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0--s6Nt1CP4F"
      },
      "source": [
        "%%capture\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *\n",
        "import pyspark.sql.functions as F\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "DP5ADlBfCRL0",
        "outputId": "4581c335-bc68-4d53-cfb5-4118f80e885f"
      },
      "source": [
        "%load_ext sparkmagic.magics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYDIPbapCSeM"
      },
      "source": [
        "%%capture\n",
        "import os\n",
        "os.environ['SPARK_HOME'] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "import pyspark\n",
        "from pyspark.sql import SQLContext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvhveK18CYOE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "b8a26e58-64de-4931-85ea-782392e3849c"
      },
      "source": [
        "try:\n",
        "    if(spark == None):\n",
        "        spark = SparkSession.builder.appName('Initial').getOrCreate()\n",
        "        sqlContext=SQLContext(spark)\n",
        "except NameError:\n",
        "    spark = SparkSession.builder.appName('Initial').getOrCreate()\n",
        "    sqlContext=SQLContext(spark)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-0416f020c561>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspark\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Initial'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-0416f020c561>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msqlContext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSQLContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mNameError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Initial'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0msqlContext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSQLContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m                             \u001b[0msparkConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                         \u001b[0;31m# This SparkContext may be an existing one.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparkConf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m                     \u001b[0;31m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                     \u001b[0;31m# by all sessions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \" is not allowed as it is a security risk.\")\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgateway\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlaunch_gateway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/java_gateway.py\u001b[0m in \u001b[0;36mlaunch_gateway\u001b[0;34m(conf, popen_kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m                     \u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGINT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIG_IGN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mpopen_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'preexec_fn'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreexec_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                 \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;31m# preexec_fn not supported on Windows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    798\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;31m# Cleanup if the child failed starting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1549\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0merrno_num\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/spark-3.1.1-bin-hadoop3.2/./bin/spark-submit': '/content/spark-3.1.1-bin-hadoop3.2/./bin/spark-submit'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH_2luN9MpUX"
      },
      "source": [
        "!pip install boto3\n",
        "import boto3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GinCjSaCzWD"
      },
      "source": [
        "**EMR Cluster Setup**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FvPLkvsDmii"
      },
      "source": [
        "#%spark delete -s my_session"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bfS-hRtDm4g"
      },
      "source": [
        "%spark add -s my_session -l python -u http://ec2-3-226-235-190.compute-1.amazonaws.com:8998"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcjtUXdZInMJ"
      },
      "source": [
        "**Import Data from S3**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTmd1pcvOIQS"
      },
      "source": [
        "%%spark\n",
        "main_sdf = spark.read.option('header','true').csv('s3://dspracticum/sdf/main_sdf/part-00000-5bbc07c6-a4b3-422e-82a3-8b3c225e0e26-c000.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD5a7NU4Imj6"
      },
      "source": [
        "%%spark\n",
        "main_sdf.createOrReplaceTempView('main_sdf')\n",
        "main_sdf.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1sSJQ6AXIaT"
      },
      "source": [
        "Condensing the spark dataframe above to include only those records where TOTALPMT is not null"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyV709DQRzRg"
      },
      "source": [
        "%%spark\n",
        "\n",
        "query = '''\n",
        "SELECT SEQNO, ORIGYEAR, WORKSTAT, LICNSTAT, LICNFELD, PRACTAGE, ALEGATN1, ALEGATN2, OUTCOME, TOTALPMT_FLOAT, TOTALPMT_ADJ, TOTALPMT_GROUP, TOTALPMT_ADJ_GROUP, PRACTEXP_ADJ, PRACTEXP_GROUP\n",
        "FROM main_sdf\n",
        "WHERE TOTALPMT IS NOT NULL\n",
        "'''\n",
        "\n",
        "main_sdf_pmt_only = spark.sql(query)\n",
        "main_sdf_pmt_only.createOrReplaceTempView('main_sdf_pmt_only')\n",
        "main_sdf_pmt_only.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fB0bkQk8XbtW"
      },
      "source": [
        "#%%spark\n",
        "#sdf_1.coalesce(1).write.format('csv').option('header','true').save('s3://dspracticum/payment_ranges_sdf/sdf_1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJEnjnl8eXnz"
      },
      "source": [
        "df = pd.read_csv('s3://dspracticum/payment_ranges_sdf/sdf_1/part-00000-dd53556e-169e-4983-93c4-e6a29c95cb7a-c000.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyCETNxB6b86"
      },
      "source": [
        "# Need to rescale payment values as range is too high to visualize\n",
        "df['total_payment_log'] = df['TOTALPMT_FLOAT'].apply(lambda x: math.log(x+1))\n",
        "df['total_payment_adjusted_log'] = df['TOTALPMT_ADJ'].apply(lambda x: math.log(x+1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obTiJ-cxiZfW"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0SIuRMWZLcH"
      },
      "source": [
        "#import alegatn1 labels\n",
        "\n",
        "alegatn1_label_df = pd.read_csv('s3://dspracticum/labels/ALEGATN1.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7856tYnBaLLN"
      },
      "source": [
        "alegatn1_label_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXuirpQBlZFU"
      },
      "source": [
        "df = df.merge(alegatn1_label_df, how = 'left', left_on = 'ALEGATN1', right_on = 'Value')\n",
        "df = df.rename(columns = {'Label': 'Allegation'})\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWSVsJ5mioWj"
      },
      "source": [
        "# import licnfeld labels\n",
        "\n",
        "licnfeld_label_df = pd.read_csv('s3://dspracticum/labels/LICNFELD.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGKewQVslEs-"
      },
      "source": [
        "licnfeld_label_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tF8UR8Ek_ws"
      },
      "source": [
        "df = df.merge(licnfeld_label_df, how = 'left', left_on = 'LICNFELD', right_on = 'Value')\n",
        "df = df.rename(columns = {'Label': 'License Field'})\n",
        "df\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYLFPHOOjHHa"
      },
      "source": [
        "# import outcome labels\n",
        "\n",
        "outcome_label_df = pd.read_csv('s3://dspracticum/labels/OUTCOME.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdSjRVvolsKP"
      },
      "source": [
        "outcome_label_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQqMq5nkbM-Y"
      },
      "source": [
        "df = df.merge(outcome_label_df, how = 'left', left_on = 'OUTCOME', right_on = 'Value')\n",
        "df = df.rename(columns = {'Label': 'Outcome'})\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTSxwK92k9mN"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6z5nJsYkorZ"
      },
      "source": [
        "I. Check the distribution of TOTALPMT in the 223,926 reports which results in totalpmt greater than zero"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptz8RJQBiIhJ"
      },
      "source": [
        "sns.displot(data = df['total_payment_log'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lDTQvmAX8Da"
      },
      "source": [
        "**FEATURES LIST**\n",
        "\n",
        "\n",
        "\n",
        "1. LICNSTAT\n",
        "2. WORKSTAT\n",
        "3. AGE\n",
        "4. PRACTEXP\n",
        "5. ALEGATN1\n",
        "6. LICNFELD\n",
        "7. OUTCOME\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Fmt96kKl7IM"
      },
      "source": [
        "Label Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Bo1axOil5p4"
      },
      "source": [
        "def label(x):\n",
        "  label = str(x)\n",
        "  if label == 'nan':\n",
        "    label = 'na'\n",
        "  else:\n",
        "    if len(label) == 3:\n",
        "      label = label[:1]\n",
        "    else:\n",
        "      label = label[:2]\n",
        "\n",
        "  return label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4fq11-NaPB4"
      },
      "source": [
        "**I. LICNSTAT and WORKSTAT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05gon6HYaVWf"
      },
      "source": [
        "%%spark\n",
        "\n",
        "query = '''\n",
        "SELECT LICNSTAT, COUNT(*) AS count, AVG(TOTALPMT_FLOAT) AS totalpmt_mean, AVG(TOTALPMT_ADJ) AS totalpmt_adj_mean\n",
        "FROM main_sdf\n",
        "WHERE TOTALPMT IS NOT NULL\n",
        "GROUP BY LICNSTAT\n",
        "ORDER BY totalpmt_adj_mean DESC\n",
        "'''\n",
        "\n",
        "sdf_2 = spark.sql(query)\n",
        "sdf_2.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynYKz8tkcrES"
      },
      "source": [
        "%%spark\n",
        "\n",
        "query = '''\n",
        "SELECT WORKSTAT, COUNT(*) AS count, AVG(TOTALPMT_FLOAT) AS totalpmt_mean, AVG(TOTALPMT_ADJ) AS totalpmt_adj_mean\n",
        "FROM main_sdf\n",
        "WHERE TOTALPMT IS NOT NULL\n",
        "GROUP BY WORKSTAT\n",
        "ORDER BY totalpmt_adj_mean DESC\n",
        "'''\n",
        "\n",
        "sdf_2 = spark.sql(query)\n",
        "sdf_2.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Qk5ijIsjNqD"
      },
      "source": [
        "%%spark\n",
        "\n",
        "query = '''\n",
        "WITH a AS (SELECT LICNSTAT, COUNT(*) AS count\n",
        "FROM main_sdf_pmt_only\n",
        "GROUP BY LICNSTAT\n",
        "ORDER BY count DESC\n",
        "LIMIT 20)\n",
        "\n",
        "SELECT *\n",
        "FROM main_sdf_pmt_only\n",
        "WHERE LICNSTAT IN (SELECT LICNSTAT FROM a)\n",
        "'''\n",
        "\n",
        "sdf_3 = spark.sql(query)\n",
        "sdf_3.createOrReplaceTempView('sdf_3')\n",
        "sdf_3.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gsqcIkapjt9"
      },
      "source": [
        "#check\n",
        "\"\"\"\n",
        "\n",
        "%%spark\n",
        "\n",
        "query = '''\n",
        "SELECT DISTINCT LICNSTAT\n",
        "FROM sdf_3'''\n",
        "\n",
        "check = spark.sql(query)\n",
        "check.count()\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGKKoI-anQby"
      },
      "source": [
        "%%spark\n",
        "sdf_3.coalesce(1).write.format('csv').option('header','true').save('s3://dspracticum/payment_ranges_sdf/top20_licnstat')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGGV8q5Pne9y"
      },
      "source": [
        "licnstat_df = pd.read_csv('s3://dspracticum/payment_ranges_sdf/top20_licnstat/part-00000-bfff0a98-f28d-4947-90a8-616149611385-c000.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GP1eB0ig_6zI"
      },
      "source": [
        "a = licnstat_df.groupby(by = ['LICNSTAT']).median()\n",
        "a = a.sort_values(by = ['TOTALPMT_FLOAT'], ascending = False)\n",
        "a = a[['TOTALPMT_FLOAT']]\n",
        "a['ORDER'] = a.index.copy()\n",
        "\n",
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nG3Q9-meF4LG"
      },
      "source": [
        "vis_order = a['ORDER']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XEh5Y6Bqyqh"
      },
      "source": [
        "# Need to rescale payment values as range is too high to visualize\n",
        "licnstat_df['total_payment_log'] = licnstat_df['TOTALPMT_FLOAT'].apply(lambda x: math.log(x+1))\n",
        "licnstat_df['total_payment_adjusted_log'] = licnstat_df['TOTALPMT_ADJ'].apply(lambda x: math.log(x+1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfEWlklAc2c3"
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (16, 8))\n",
        "sns.boxplot(x = \"total_payment_log\", y = \"LICNSTAT\", data = licnstat_df, order = vis_order)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBKEmbdEH-7w"
      },
      "source": [
        "The above shows only top 20 counts. Lets try to do all states"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HLWvLHqYpJM"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9dNoDrWOcpt"
      },
      "source": [
        "LICNSTAT - total_payment_log"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcuJLAdZIQue"
      },
      "source": [
        "a = df.groupby(by = ['LICNSTAT']).median()\n",
        "a = a.sort_values(by = ['total_payment_log'], ascending = False)\n",
        "a = a[['total_payment_log']]\n",
        "a['ORDER'] = a.index.copy()\n",
        "\n",
        "vis_order = a['ORDER']\n",
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqIx6v-fKTQB"
      },
      "source": [
        "LICNSTAT - total_payment_log"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX6jPuwKI-Jk"
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (16, 24))\n",
        "sns.boxplot(x = \"total_payment_log\", y = \"LICNSTAT\", data = df, order = vis_order, palette = 'crest_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATSWef0kKaBg"
      },
      "source": [
        "LICNSTAT - total_payment_adjusted_log - median"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iyrvU5YOuJL"
      },
      "source": [
        "a = df.groupby(by = ['LICNSTAT']).median()\n",
        "a = a.sort_values(by = ['total_payment_adjusted_log'], ascending = False)\n",
        "a = a[['total_payment_adjusted_log']]\n",
        "a['ORDER'] = a.index.copy()\n",
        "\n",
        "vis_order = a['ORDER']\n",
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsLcMgcAKa7A"
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (16, 24))\n",
        "sns.boxplot(x = \"total_payment_adjusted_log\", y = \"LICNSTAT\", data = df, order = vis_order, palette = 'flare_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlZcv-CHYbTc"
      },
      "source": [
        "**WORKSTAT**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRtmQLPNRUad"
      },
      "source": [
        "WORKSTAT - total_payment_log - median"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlPVe1ltRbkp"
      },
      "source": [
        "a = df.groupby(by = ['WORKSTAT']).median()\n",
        "a = a.sort_values(by = ['total_payment_log'], ascending = False)\n",
        "a = a[['total_payment_log']]\n",
        "a['ORDER'] = a.index.copy()\n",
        "\n",
        "vis_order = a['ORDER']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEyTDUz1Rbg8"
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (16, 24))\n",
        "sns.boxplot(x = \"total_payment_log\", y = \"WORKSTAT\", data = df, order = vis_order, palette = 'crest_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIuhKjTPSe9R"
      },
      "source": [
        "WORKSTAT - total_payment_adjusted_log - median"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45MuZBS_Rv1M"
      },
      "source": [
        "a = df.groupby(by = ['WORKSTAT']).median()\n",
        "a = a.sort_values(by = ['total_payment_adjusted_log'], ascending = False)\n",
        "a = a[['total_payment_adjusted_log']]\n",
        "a['ORDER'] = a.index.copy()\n",
        "\n",
        "vis_order = a['ORDER']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF_DcZW0Ry1S"
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (16, 24))\n",
        "sns.boxplot(x = \"total_payment_adjusted_log\", y = \"WORKSTAT\", data = df, order = vis_order, palette = 'flare_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Aog7Cm3Sea6"
      },
      "source": [
        "**PRACTAGE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12WI62wyYtlv"
      },
      "source": [
        "PRACTAGE - total_payment_log - median"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z8QsgcLkhLl"
      },
      "source": [
        "df_copy = df.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFpbaIutlBTk"
      },
      "source": [
        "df_copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oANGSKpklqEp"
      },
      "source": [
        "df_copy['Practitioner Age Group'] = df_copy['PRACTAGE'].apply(lambda x: label(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_Vqd50FYiJN"
      },
      "source": [
        "a = df_copy.groupby(by = ['Practitioner Age Group']).median()\n",
        "\n",
        "a = a[['total_payment_log']]\n",
        "a['ORDER'] = a.index.copy()\n",
        "a = a.sort_values(by = ['ORDER'], ascending = False)\n",
        "\n",
        "vis_order = a['ORDER']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOGFKqlngImi"
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4EDMxqRYiDG"
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (16, 8))\n",
        "sns.boxplot(x = \"total_payment_log\", y = \"Practitioner Age Group\", data = df_copy, order = vis_order, palette = 'crest_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iYZrme9Y1mp"
      },
      "source": [
        "PRACTAGE - total_payment_adjusted_log - median"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TVEc-rFYh8z"
      },
      "source": [
        "a = df_copy.groupby(by = ['Practitioner Age Group']).median()\n",
        "\n",
        "a = a[['total_payment_adjusted_log']]\n",
        "a['ORDER'] = a.index.copy()\n",
        "a = a.sort_values(by = ['ORDER'], ascending = False)\n",
        "\n",
        "vis_order = a['ORDER']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUDO_crIYh2O"
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (16, 8))\n",
        "sns.boxplot(x = \"total_payment_adjusted_log\", y = \"Practitioner Age Group\", data = df_copy, order = vis_order, palette = 'flare_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc1185HyZ9Qk"
      },
      "source": [
        "**PRACTEXP**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNxvbwzgdq6x"
      },
      "source": [
        "PRACTEXP - total_payment_log - median"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UJ1LKP_qstl"
      },
      "source": [
        "df_copy = df.copy()\n",
        "df_copy['Practitioner Experience'] = df_copy['PRACTEXP_GROUP'].apply(lambda x: label(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyF8_rm9dqx2"
      },
      "source": [
        "a = df_copy.groupby(by = ['Practitioner Experience']).median()\n",
        "\n",
        "a = a[['total_payment_log']]\n",
        "a['ORDER'] = a.index.copy()\n",
        "a = a.sort_values(by = ['ORDER'], ascending = False)\n",
        "\n",
        "vis_order = a['ORDER']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGAd54puq3a5"
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9m4kyFlkdql_"
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (16, 8))\n",
        "sns.boxplot(x = \"total_payment_log\", y = \"Practitioner Experience\", data = df_copy, order = vis_order, palette = 'crest_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W82IPuYYdrdD"
      },
      "source": [
        "PRACTEXP - total_payment_log - median"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dYzqMatdqb5"
      },
      "source": [
        "a = df_copy.groupby(by = ['Practitioner Experience']).median()\n",
        "\n",
        "a = a[['total_payment_adjusted_log']]\n",
        "a['ORDER'] = a.index.copy()\n",
        "a = a.sort_values(by = ['ORDER'], ascending = False)\n",
        "\n",
        "vis_order = a['ORDER']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsA631bOdqX-"
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (16, 8))\n",
        "sns.boxplot(x = \"total_payment_adjusted_log\", y = \"Practitioner Experience\", data = df_copy, order = vis_order, palette = 'flare_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g34JZ9JeFXA"
      },
      "source": [
        "**ALEGATN1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwj9XtBVeL6e"
      },
      "source": [
        "ALEGATN1 - total_payment_log - median"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm6BnbjGdSMs"
      },
      "source": [
        "df_copy = df.copy()\n",
        "df_copy['Allegation'] = df_copy['Label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIN2x4RZeLJJ"
      },
      "source": [
        "a = df_copy.groupby(by = ['Allegation']).median()\n",
        "a = a.sort_values(by = ['total_payment_log'], ascending = False)\n",
        "a = a[['total_payment_log']]\n",
        "a['ORDER'] = a.index.copy()\n",
        "\n",
        "vis_order = a['ORDER']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLK_JWX9sLSN"
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl4S1S3leLjI"
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (16, 24))\n",
        "sns.boxplot(x = \"total_payment_log\", y = \"Allegation\", data = df_copy, order = vis_order, palette = 'crest_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu3PC4OHeMqm"
      },
      "source": [
        "ALEGATN1 - total_payment_adjusted_log - median"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rhpjBoyeLbK"
      },
      "source": [
        "a = df_copy.groupby(by = ['Allegation']).median()\n",
        "a = a.sort_values(by = ['total_payment_adjusted_log'], ascending = False)\n",
        "a = a[['total_payment_log']]\n",
        "a['ORDER'] = a.index.copy()\n",
        "\n",
        "vis_order = a['ORDER']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZh_WSo3eLM7"
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (16, 24))\n",
        "sns.boxplot(x = \"total_payment_adjusted_log\", y = \"Allegation\", data = df_copy, order = vis_order, palette = 'flare_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFHHm-gqeoku"
      },
      "source": [
        "**LICNFELD**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a70U7Ylqe6zu"
      },
      "source": [
        "LICNFELD - total_payment_log - median"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha91equihJ7x"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywyez3lRhDN9"
      },
      "source": [
        "df.groupby(by = ['License Field']).median()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWTHBsFye4M-"
      },
      "source": [
        "a = df.groupby(by = ['License Field']).median()\n",
        "a = a.sort_values(by = ['total_payment_log'], ascending = False)\n",
        "a = a[['total_payment_log']]\n",
        "a['ORDER'] = a.index.copy()\n",
        "\n",
        "vis_order = a['ORDER']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfBC0Doag1i3"
      },
      "source": [
        "vis_order"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k15H90uhe4wl"
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (16, 36))\n",
        "sns.boxplot(x = \"total_payment_log\", y = \"License Field\", data = df, order = vis_order, palette = 'crest_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pisdQ4Nme87G"
      },
      "source": [
        "LICNFELD - total_payment_adjusted_log - median"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47G6sInWe4st"
      },
      "source": [
        "a = df.groupby(by = ['License Field']).median()\n",
        "a = a.sort_values(by = ['total_payment_adjusted_log'], ascending = False)\n",
        "a = a[['total_payment_adjusted_log']]\n",
        "a['ORDER'] = a.index.copy()\n",
        "\n",
        "vis_order = a['ORDER']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iGcchb-e4jK"
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (16, 36))\n",
        "sns.boxplot(x = \"total_payment_adjusted_log\", y = \"License Field\", data = df, order = vis_order, palette = 'flare_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZVVXb0jet5V"
      },
      "source": [
        "**OUTCOME**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuMTKBdffLDg"
      },
      "source": [
        "OUTCOME - total_payment_log - median"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPWFWsjOe6Lw"
      },
      "source": [
        "a = df.groupby(by = ['Outcome']).median()\n",
        "a = a.sort_values(by = ['total_payment_log'], ascending = False)\n",
        "a = a[['total_payment_log']]\n",
        "a['ORDER'] = a.index.copy()\n",
        "\n",
        "vis_order = a['ORDER']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzcc4JIEe5_D"
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (16, 10))\n",
        "sns.boxplot(x = \"total_payment_log\", y = \"Outcome\", data = df, order = vis_order, palette = 'crest_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY5MRhyrfJDA"
      },
      "source": [
        "OUTCOME - total_payment_adjusted_log - median"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUBR5S3we57N"
      },
      "source": [
        "a = df.groupby(by = ['Outcome']).median()\n",
        "a = a.sort_values(by = ['total_payment_adjusted_log'], ascending = False)\n",
        "a = a[['total_payment_adjusted_log']]\n",
        "a['ORDER'] = a.index.copy()\n",
        "\n",
        "vis_order = a['ORDER']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bQu8Tl6e5kN"
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (16, 10))\n",
        "sns.boxplot(x = \"total_payment_adjusted_log\", y = \"Outcome\", data = df, order = vis_order, palette = 'flare_r')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}